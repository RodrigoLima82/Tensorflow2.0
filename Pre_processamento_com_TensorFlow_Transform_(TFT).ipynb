{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-processamento com TensorFlow Transform (TFT).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoLima82/Tensorflow2.0/blob/master/Pre_processamento_com_TensorFlow_Transform_(TFT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrTvQdliQwfq",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 1: Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMz_jKWTQnMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrLStnUMRkRJ",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 2: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdITrI4DRcU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tempfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "import tensorflow_transform.beam.impl as tft_beam\n",
        "\n",
        "from __future__ import print_function\n",
        "from tensorflow_transform.tf_metadata import dataset_metadata, dataset_schema"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt7k2HebR5FS",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 3: Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozq6hsu1R8lx",
        "colab_type": "text"
      },
      "source": [
        "### Carregando a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1c70dDqfM6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"pollution-small.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_UKZ2f2faku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ezQp6pR_iS",
        "colab_type": "text"
      },
      "source": [
        "### Apagando a coluna com a data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx48EIDJforq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = dataset.drop(\"Date\", axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAsPmQDUfxG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqAeENlvSDFJ",
        "colab_type": "text"
      },
      "source": [
        "### Conversão da base de dados (dataframe) para dicionário\n",
        "\n",
        "Mais sobre dicionários: https://iaexpert.com.br/index.php/2019/09/12/dicionarios-em-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYi0-eV5gMK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_features = list(features.to_dict(\"index\").values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh1gfQkagbod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_features[0:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Uj7Ha0T8Y7",
        "colab_type": "text"
      },
      "source": [
        "### Definição dos metadados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgJSBI7hhh77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_metadata = dataset_metadata.DatasetMetadata(dataset_schema.from_feature_spec({\n",
        "    \"no2\": tf.FixedLenFeature([], tf.float32),\n",
        "    \"pm10\": tf.FixedLenFeature([], tf.float32),\n",
        "    \"so2\": tf.FixedLenFeature([], tf.float32),\n",
        "    \"soot\": tf.FixedLenFeature([], tf.float32),\n",
        "}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spku-W-8inHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_metadata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyxr8dE6VwVe",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 4: Função para pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkv-8VHVjUjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_fn(inputs):\n",
        "  no2 = inputs[\"no2\"]\n",
        "  pm10 = inputs[\"pm10\"]\n",
        "  so2 = inputs[\"so2\"]\n",
        "  soot = inputs[\"soot\"]\n",
        "  \n",
        "  no2_normalized = no2 - tft.mean(no2)\n",
        "  so2_normalized = so2 - tft.mean(so2)\n",
        "  \n",
        "  pm10_normalized = tft.scale_to_0_1(pm10)\n",
        "  soot_normalized = tft.scale_by_min_max(soot)\n",
        "  \n",
        "  return {\n",
        "      \"no2_normalized\": no2_normalized,\n",
        "      \"so2_normalized\": so2_normalized,\n",
        "      \"pm10_normalized\": pm10_normalized,\n",
        "      \"sott_normalized\": soot_normalized\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqt-Hb7EX1rU",
        "colab_type": "text"
      },
      "source": [
        "## Etapa 5: Unindo a codificação\n",
        "\n",
        "O Tensorflow Transform usa o **Apache Beam** como background para realizar as operações. \n",
        "\n",
        "Parâmetros a serem passados para a função:\n",
        "\n",
        "    dict_features - Nossa base de dados convertida para dicionário\n",
        "    data_metadata - Nossos metadados que criamos anteriormente\n",
        "    preprocessing_fn - Função de pré-processamento que fará as transformações coluna por coluna\n",
        "\n",
        "\n",
        "Abaixo temos a sintaxe usada pelo Apache Beam\n",
        "\n",
        "```\n",
        "result = data_to_pass | where_to_pass_the_data\n",
        "```\n",
        "\n",
        "Explicando cada um dos parâmetros:\n",
        "\n",
        "**result**  -> `transformed_dataset, transform_fn`\n",
        "\n",
        "**data_to_pass** -> `(dict_features, data_metadata)`\n",
        "\n",
        "**where_to_pass_the_data** -> `tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)` \n",
        "\n",
        "```\n",
        "transformed_dataset, transform_fn = ((dict_features, data_metadata) | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
        "\n",
        "```\n",
        "\n",
        "Mais sobre essa sintaxe: \n",
        "https://beam.apache.org/documentation/programming-guide/#applying-transforms\n",
        "\n",
        "LINKS:\n",
        "> Mais sobre o Apache Beam: https://beam.apache.org/ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1CLHmD6mp50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_transform():\n",
        "  with tft_beam.Context(temp_dir = tempfile.mkdtemp()):\n",
        "    transformed_dataset, transform_fn = ((dict_features, data_metadata) | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
        "    \n",
        "  transformed_data, transformed_metadata = transformed_dataset\n",
        "  \n",
        "  for i in range(len(transformed_data)):\n",
        "    print(\"Initial: \", dict_features[i])\n",
        "    print(\"Transformed: \", transformed_data[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV2kg-6ngVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}